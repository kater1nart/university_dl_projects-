{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a564d5f",
      "metadata": {
        "id": "3a564d5f"
      },
      "source": [
        "# Введение в RL и пакет Gymnasium\n",
        "\n",
        "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
        "\n",
        "Материалы:\n",
        "* https://gymnasium.farama.org/\n",
        "* https://pypi.org/project/ufal.pybox2d/\n",
        "* https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/\n",
        "* https://gymnasium.farama.org/api/spaces/fundamental/\n",
        "* https://gymnasium.farama.org/environments/toy_text/blackjack/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9ecd663",
      "metadata": {
        "id": "c9ecd663"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b79f4f",
      "metadata": {
        "id": "96b79f4f"
      },
      "source": [
        "1\\. Рассмотрите пример создания окружения `gymnasium` и основные этапы взаимодействия с этим окружением.\n",
        "\n",
        "<img src=\"https://gymnasium.farama.org/_images/AE_loop.png\" width=\"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7b6d63",
      "metadata": {
        "id": "4d7b6d63"
      },
      "source": [
        "## Задачи для самостоятельного решения"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f49190d",
      "metadata": {
        "id": "7f49190d"
      },
      "source": [
        "<p class=\"task\" id=\"1\"></p>\n",
        "\n",
        "1\\. Создайте окружение `Blackjack-v1`. Сыграйте `N=10000` игр, выбирая действие случайным образом. Посчитайте и выведите на экран долю выигранных игр.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bac0976-e9c0-4131-aba1-a56eecfdaded",
      "metadata": {
        "id": "7bac0976-e9c0-4131-aba1-a56eecfdaded",
        "outputId": "e5deff3f-767d-467e-feed-927938858325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сыграно игр: 10000\n",
            "Побед: 2803\n",
            "Ничьих: 439\n",
            "Поражений: 6758\n",
            "Доля выигрышей (Win Rate): 0.2803 (28.03%)\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from tqdm import tqdm\n",
        "\n",
        "env = gym.make('Blackjack-v1', render_mode=None)\n",
        "\n",
        "N_GAMES = 10_000\n",
        "wins = 0\n",
        "draws = 0\n",
        "losses = 0\n",
        "\n",
        "for _ in range(N_GAMES):\n",
        "    state, info = env.reset()\n",
        "\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            if reward == 1.0:\n",
        "                wins += 1\n",
        "            elif reward == 0.0:\n",
        "                draws += 1\n",
        "            else: # reward == -1.0\n",
        "                losses += 1\n",
        "\n",
        "env.close()\n",
        "win_rate = wins / N_GAMES\n",
        "print(f\"Сыграно игр: {N_GAMES}\")\n",
        "print(f\"Побед: {wins}\")\n",
        "print(f\"Ничьих: {draws}\")\n",
        "print(f\"Поражений: {losses}\")\n",
        "print(f\"Доля выигрышей (Win Rate): {win_rate:.4f} ({win_rate * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2956c0",
      "metadata": {
        "id": "3e2956c0"
      },
      "source": [
        "<p class=\"task\" id=\"2\"></p>\n",
        "\n",
        "2\\. Создайте окружение `Blackjack-v1`. Предложите стратегию, которая позволит, в среднем, выигрывать чаще, чем случайный выбор действия. Реализуйте эту стратегию и сыграйте `N=10000` игр, выбирая действие согласно этой стратегии. Посчитайте и выведите на экран долю выигранных игр.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3cca1b-cc06-4535-8316-46ebef81a12e",
      "metadata": {
        "id": "3e3cca1b-cc06-4535-8316-46ebef81a12e",
        "outputId": "323d67a1-6251-4161-ffac-2ea792366855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сыграно игр: 10000\n",
            "Побед: 4119\n",
            "Ничьих: 1009\n",
            "Доля выигрышей (Win Rate): 0.4119 (41.19%)\n"
          ]
        }
      ],
      "source": [
        "def simple_strategy(observation):\n",
        "\n",
        "    player_sum, dealer_card, usable_ace = observation\n",
        "    if player_sum < 17:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "env = gym.make('Blackjack-v1', render_mode=None)\n",
        "N_GAMES = 10_000\n",
        "wins = 0\n",
        "draws = 0\n",
        "losses = 0\n",
        "\n",
        "for _ in range(N_GAMES):\n",
        "    state, info = env.reset()\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action = simple_strategy(state)\n",
        "\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        if terminated or truncated:\n",
        "            if reward == 1.0:\n",
        "                wins += 1\n",
        "            elif reward == 0.0:\n",
        "                draws += 1\n",
        "            else:\n",
        "                losses += 1\n",
        "\n",
        "env.close()\n",
        "\n",
        "win_rate = wins / N_GAMES\n",
        "print(f\"Сыграно игр: {N_GAMES}\")\n",
        "print(f\"Побед: {wins}\")\n",
        "print(f\"Ничьих: {draws}\")\n",
        "print(f\"Доля выигрышей (Win Rate): {win_rate:.4f} ({win_rate * 100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2698c28",
      "metadata": {
        "id": "f2698c28"
      },
      "source": [
        "<p class=\"task\" id=\"3\"></p>\n",
        "\n",
        "3\\. Создайте окружение для игры в крестики-нолики, реализовав интерфейс `gym.Env`. Решение должно удовлетворять следующим условиям:\n",
        "* для создания пространства состояний используется `spaces.Box`;\n",
        "* для создания пространства действий используется `spaces.MultiDiscrete`;\n",
        "* игра прекращается, если:\n",
        "    - нет возможности сделать ход;\n",
        "    - игрок пытается отметить уже выбранную ячейку.\n",
        "* после каждого хода игрок получает награду:\n",
        "    - 0, если игра не закончена;\n",
        "    - 1, если игрок выиграл;\n",
        "    - -1, если игрок проиграл.\n",
        "* стратегию выбора действия для второго игрока (машины) определите самостоятельно.\n",
        "\n",
        "Стратегия поведения машины является частью окружения и должна быть реализована внутри него. Сделайте все соответствующие переменные и методы приватными (названия всех переменных начинаются с `__`), подчеркнув, что у пользователя не должно быть к ним доступа извне.\n",
        "\n",
        "Сыграйте одну игру, выбирая действия случайным образом. Выведите на экран состояние окружения после каждого хода и итоговую награду пользователя за сессию.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a76a17-5d94-4635-b839-a2eab9a45577",
      "metadata": {
        "id": "78a76a17-5d94-4635-b839-a2eab9a45577",
        "outputId": "25527bf1-9ea1-436b-d198-5b7b55b1e905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Начинаем игру в Крестики-Нолики!\n",
            "-----\n",
            " | | \n",
            " | | \n",
            " | | \n",
            "-----\n",
            "Игрок выбирает клетку: [2 0]\n",
            "-----\n",
            "O| | \n",
            " | | \n",
            "X| | \n",
            "-----\n",
            "Игрок выбирает клетку: [0 0]\n",
            "-----\n",
            "O| | \n",
            " | | \n",
            "X| | \n",
            "-----\n",
            "Игра окончена. Награда: -1\n",
            "Инфо: {'info': 'Invalid move'}\n"
          ]
        }
      ],
      "source": [
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class TicTacToeEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.action_space = spaces.MultiDiscrete([3, 3])\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=2, shape=(3, 3), dtype=np.int8\n",
        "        )\n",
        "\n",
        "        self.__board = None\n",
        "        self.__player_mark = 1\n",
        "        self.__bot_mark = 2\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.__board = np.zeros((3, 3), dtype=np.int8)\n",
        "\n",
        "        return self.__board, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        row, col = action\n",
        "\n",
        "        if self.__board[row, col] != 0:\n",
        "            return self.__board, -1, True, False, {\"info\": \"Invalid move\"}\n",
        "\n",
        "        self.__board[row, col] = self.__player_mark\n",
        "\n",
        "        if self.__check_winner(self.__player_mark):\n",
        "            return self.__board, 1, True, False, {\"info\": \"Player won\"}\n",
        "\n",
        "        if self.__is_full():\n",
        "            return self.__board, 0, True, False, {\"info\": \"Draw\"}\n",
        "\n",
        "        self.__bot_step()\n",
        "\n",
        "        if self.__check_winner(self.__bot_mark):\n",
        "            return self.__board, -1, True, False, {\"info\": \"Bot won\"}\n",
        "\n",
        "        if self.__is_full():\n",
        "            return self.__board, 0, True, False, {\"info\": \"Draw\"}\n",
        "\n",
        "        return self.__board, 0, False, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(\"-\" * 5)\n",
        "        for row in self.__board:\n",
        "            print('|'.join(['X' if x==1 else 'O' if x==2 else ' ' for x in row]))\n",
        "        print(\"-\" * 5)\n",
        "\n",
        "\n",
        "    def __bot_step(self):\n",
        "        empty_cells = np.argwhere(self.__board == 0)\n",
        "        if len(empty_cells) > 0:\n",
        "            chosen_idx = self.np_random.integers(0, len(empty_cells))\n",
        "            move = empty_cells[chosen_idx]\n",
        "            self.__board[move[0], move[1]] = self.__bot_mark\n",
        "\n",
        "    def __check_winner(self, mark):\n",
        "        for i in range(3):\n",
        "            if np.all(self.__board[i, :] == mark) or np.all(self.__board[:, i] == mark):\n",
        "                return True\n",
        "        if self.__board[0, 0] == mark and self.__board[1, 1] == mark and self.__board[2, 2] == mark:\n",
        "            return True\n",
        "        if self.__board[0, 2] == mark and self.__board[1, 1] == mark and self.__board[2, 0] == mark:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def __is_full(self):\n",
        "        return not np.any(self.__board == 0)\n",
        "env = TicTacToeEnv()\n",
        "\n",
        "print(\"Начинаем игру в Крестики-Нолики!\")\n",
        "obs, _ = env.reset()\n",
        "env.render()\n",
        "\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    print(f\"Игрок выбирает клетку: {action}\")\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    total_reward += reward\n",
        "\n",
        "    env.render()\n",
        "    if done:\n",
        "        print(f\"Игра окончена. Награда: {reward}\")\n",
        "        print(f\"Инфо: {info}\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdcd8fa6",
      "metadata": {
        "id": "cdcd8fa6"
      },
      "source": [
        "<p class=\"task\" id=\"4\"></p>\n",
        "\n",
        "4\\. Предложите стратегию (в виде алгоритма без использования методов машинного обучения), которая позволит, в среднем, выигрывать в крестики-нолики чаще, чем случайный выбор действия. Реализуйте эту стратегию и сыграйте игру, выбирая действия согласно этой стратегии. Выведите на экран состояние окружения после каждого хода и итоговую награду пользователя за сессию.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c173c791-e165-4e99-99e1-d05160201dfd",
      "metadata": {
        "id": "c173c791-e165-4e99-99e1-d05160201dfd",
        "outputId": "5caca1b8-2951-4b19-cd71-334f79473836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Начинаем игру: Умный Агент vs Рандомный Бот ===\n",
            "-----\n",
            " | | \n",
            " | | \n",
            " | | \n",
            "-----\n",
            "\n",
            "Агент ходит в: [1 1]\n",
            "-----\n",
            " | | \n",
            "O|X| \n",
            " | | \n",
            "-----\n",
            "\n",
            "Агент ходит в: [0 0]\n",
            "-----\n",
            "X| | \n",
            "O|X| \n",
            "O| | \n",
            "-----\n",
            "\n",
            "Агент ходит в: [2 2]\n",
            "-----\n",
            "X| | \n",
            "O|X| \n",
            "O| |X\n",
            "-----\n",
            "\n",
            "Итог: ПОБЕДА Агента!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def check_potential_win(board, mark):\n",
        "    empty_cells = np.argwhere(board == 0)\n",
        "\n",
        "    for cell in empty_cells:\n",
        "        r, c = cell\n",
        "        temp_board = board.copy()\n",
        "        temp_board[r, c] = mark\n",
        "\n",
        "        if np.all(temp_board[r, :] == mark) or np.all(temp_board[:, c] == mark):\n",
        "            return (r, c)\n",
        "\n",
        "        if (r == c) or (r + c == 2):\n",
        "            if (temp_board[0, 0] == mark and temp_board[1, 1] == mark and temp_board[2, 2] == mark):\n",
        "                return (r, c)\n",
        "            if (temp_board[0, 2] == mark and temp_board[1, 1] == mark and temp_board[2, 0] == mark):\n",
        "                return (r, c)\n",
        "\n",
        "    return None\n",
        "\n",
        "def smart_agent_action(board):\n",
        "    PLAYER_MARK = 1\n",
        "    BOT_MARK = 2\n",
        "    win_move = check_potential_win(board, PLAYER_MARK)\n",
        "    if win_move is not None:\n",
        "        return np.array(win_move)\n",
        "\n",
        "    block_move = check_potential_win(board, BOT_MARK)\n",
        "    if block_move is not None:\n",
        "        return np.array(block_move)\n",
        "    if board[1, 1] == 0:\n",
        "        return np.array([1, 1])\n",
        "\n",
        "    corners = [[0, 0], [0, 2], [2, 0], [2, 2]]\n",
        "    available_corners = [c for c in corners if board[c[0], c[1]] == 0]\n",
        "    if len(available_corners) > 0:\n",
        "        idx = np.random.randint(len(available_corners))\n",
        "        return np.array(available_corners[idx])\n",
        "\n",
        "    empty_cells = np.argwhere(board == 0)\n",
        "    if len(empty_cells) > 0:\n",
        "        idx = np.random.randint(len(empty_cells))\n",
        "        return empty_cells[idx]\n",
        "\n",
        "    return np.array([0, 0])\n",
        "\n",
        "env = TicTacToeEnv()\n",
        "\n",
        "print(\"=== Начинаем игру: Умный Агент vs Рандомный Бот ===\")\n",
        "obs, _ = env.reset()\n",
        "env.render()\n",
        "\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = smart_agent_action(obs)\n",
        "    print(f\"\\nАгент ходит в: {action}\")\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "    done = terminated or truncated\n",
        "\n",
        "    if done:\n",
        "        if reward == 1:\n",
        "            print(\"\\nИтог: ПОБЕДА Агента!\")\n",
        "        elif reward == -1:\n",
        "            print(\"\\nИтог: ПОРАЖЕНИЕ (Бот выиграл)!\")\n",
        "        else:\n",
        "            print(\"\\nИтог: НИЧЬЯ!\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0992c961",
      "metadata": {
        "id": "0992c961"
      },
      "source": [
        "<p class=\"task\" id=\"5\"></p>\n",
        "\n",
        "5\\. Создайте окружение `MountainCar-v0`. Проиграйте 10 эпизодов и сохраните на диск файл с записью каждого пятого эпизода. Для записи видео воспользуйтесь обёрткой `RecordVideo`. Вставьте скриншот, на котором видно, что файлы были созданы.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2385a2d9-936e-404b-8e07-47e2b566691b",
      "metadata": {
        "id": "2385a2d9-936e-404b-8e07-47e2b566691b",
        "outputId": "23621189-4107-4797-bf72-77cd173b5418"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Conda_Envs\\aio_project_d\\lib\\site-packages\\gymnasium\\wrappers\\rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at D:\\Jupik\\video_mountain_car folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Начинаем симуляцию...\n",
            "Эпизод 0 завершен. Видео должно быть записано.\n",
            "Эпизод 5 завершен. Видео должно быть записано.\n",
            "Эпизод 10 завершен. Видео должно быть записано.\n",
            "Эпизод 15 завершен. Видео должно быть записано.\n",
            "Эпизод 20 завершен. Видео должно быть записано.\n",
            "Эпизод 25 завершен. Видео должно быть записано.\n",
            "Эпизод 30 завершен. Видео должно быть записано.\n",
            "Эпизод 35 завершен. Видео должно быть записано.\n",
            "Эпизод 40 завершен. Видео должно быть записано.\n",
            "Эпизод 45 завершен. Видео должно быть записано.\n",
            "Найдены видеофайлы: ['rl-video-episode-0.mp4', 'rl-video-episode-10.mp4', 'rl-video-episode-15.mp4', 'rl-video-episode-20.mp4', 'rl-video-episode-25.mp4', 'rl-video-episode-30.mp4', 'rl-video-episode-35.mp4', 'rl-video-episode-40.mp4', 'rl-video-episode-45.mp4', 'rl-video-episode-5.mp4']\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import os\n",
        "\n",
        "base_env = gym.make('MountainCar-v0', render_mode='rgb_array')\n",
        "\n",
        "trigger = lambda episode_id: episode_id % 5 == 0\n",
        "env = RecordVideo(base_env, video_folder=\"./video_mountain_car\", episode_trigger=trigger, disable_logger=True)\n",
        "\n",
        "N_EPISODES = 50\n",
        "\n",
        "print(\"Начинаем симуляцию...\")\n",
        "\n",
        "for i in range(N_EPISODES):\n",
        "    obs, info = env.reset()\n",
        "    terminated = truncated = False\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "    if trigger(i):\n",
        "        print(f\"Эпизод {i} завершен. Видео должно быть записано.\")\n",
        "\n",
        "env.close()\n",
        "try:\n",
        "    files = os.listdir(\"./video_mountain_car\")\n",
        "    mp4_files = [f for f in files if f.endswith('.mp4')]\n",
        "    print(f\"Найдены видеофайлы: {mp4_files}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Папка с видео не найдена. Что-то пошло не так.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e08c69d-9177-405c-a223-05a0eb1dfc80",
      "metadata": {
        "id": "9e08c69d-9177-405c-a223-05a0eb1dfc80"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (AIOps on D)",
      "language": "python",
      "name": "aio_project_d"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}