{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a564d5f",
      "metadata": {
        "id": "3a564d5f"
      },
      "source": [
        "#  Forward pass\n",
        "\n",
        "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
        "\n",
        "Материалы:\n",
        "* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann\n",
        "* https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "* https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
        "* https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/\n",
        "* https://kidger.site/thoughts/jaxtyping/\n",
        "* https://github.com/patrick-kidger/torchtyping/tree/master"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9ecd663",
      "metadata": {
        "id": "c9ecd663"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b6ed92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82b6ed92",
        "outputId": "f25b69fb-a8ef-42c8-8184-2942ced02e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtyping\n",
            "  Downloading torchtyping-0.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from torchtyping) (2.8.0+cu126)\n",
            "Collecting typeguard<3,>=2.11.1 (from torchtyping)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->torchtyping) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (3.0.2)\n",
            "Downloading torchtyping-0.1.5-py3-none-any.whl (17 kB)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, torchtyping\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.4\n",
            "    Uninstalling typeguard-4.4.4:\n",
            "      Successfully uninstalled typeguard-4.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchtyping-0.1.5 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "pip install torchtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7ad9ed",
      "metadata": {
        "id": "3f7ad9ed"
      },
      "outputs": [],
      "source": [
        "from torchtyping import TensorType, patch_typeguard\n",
        "from typeguard import typechecked\n",
        "import torch as th\n",
        "\n",
        "Scalar = TensorType[()]\n",
        "patch_typeguard()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a87d01a9",
      "metadata": {
        "id": "a87d01a9"
      },
      "source": [
        "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте нейрон с заданными весами `weights` и `bias`. Пропустите вектор `inputs` через нейрон и выведите результат."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "    def __init__(self, n_features):\n",
        "        self.weights = th.randn(n_features)\n",
        "        self.bias = th.randn(1)\n",
        "        print(self.bias, self.weights)\n",
        "\n",
        "    def forward(self, inputs: TensorType[\"n_features\"]) -> Scalar:\n",
        "        return inputs.dot(self.weights) + self.bias"
      ],
      "metadata": {
        "id": "EZWEw7ONaI0e"
      },
      "id": "EZWEw7ONaI0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\n",
        "inputs = th.tensor([1.0, 2.0, 3.0, 4.0])"
      ],
      "metadata": {
        "id": "Y1CvoRhyaqCb"
      },
      "id": "Y1CvoRhyaqCb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron(4)\n",
        "neuron.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ_GH83aaqJy",
        "outputId": "2b9844ff-2646-473e-ee67-af51a9dad866"
      },
      "id": "EQ_GH83aaqJy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4384]) tensor([-0.8734,  0.0820, -0.2416, -0.4198])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.5522])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e5fe51",
      "metadata": {
        "id": "32e5fe51"
      },
      "source": [
        "2\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ReLU:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f4353f4e3e484130504049599d2e7b040793e1eb)\n",
        "\n",
        "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    @typechecked\n",
        "    def forward(self, inputs: TensorType) -> TensorType:\n",
        "        return th.clamp(inputs, min=0)"
      ],
      "metadata": {
        "id": "-J9JT45804to"
      },
      "id": "-J9JT45804to",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_matrix = th.randn(4, 3)\n",
        "relu_activation = ReLU()\n",
        "output_matrix = relu_activation.forward(input_matrix)\n",
        "\n",
        "print(\"Входная матрица:\\n\", input_matrix)\n",
        "print(\"Матрица после применения ReLU:\\n\", output_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq19smin1JPs",
        "outputId": "1ee58f1f-afee-4327-8f79-53d9e7301627"
      },
      "id": "Kq19smin1JPs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входная матрица:\n",
            " tensor([[ 1.1212,  0.1854,  0.3594],\n",
            "        [ 0.6683,  0.3058,  0.3114],\n",
            "        [-0.0315, -0.3334,  1.7900],\n",
            "        [-0.4768, -0.9121, -0.4716]])\n",
            "Матрица после применения ReLU:\n",
            " tensor([[1.1212, 0.1854, 0.3594],\n",
            "        [0.6683, 0.3058, 0.3114],\n",
            "        [0.0000, 0.0000, 1.7900],\n",
            "        [0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a16748",
      "metadata": {
        "id": "c6a16748"
      },
      "source": [
        "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь MSE:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e)\n",
        "где $Y_i$ - правильный ответ для примера $i$, $\\hat{Y_i}$ - предсказание модели для примера $i$, $n$ - количество примеров в батче."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e046dfa6",
      "metadata": {
        "id": "e046dfa6"
      },
      "outputs": [],
      "source": [
        "class MSELoss:\n",
        "    @typechecked\n",
        "    def forward(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"]) -> Scalar:\n",
        "        return # <реализовать логику MSE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e686f8b8",
      "metadata": {
        "id": "e686f8b8"
      },
      "outputs": [],
      "source": [
        "y_pred = th.tensor([1.0, 3.0, 5.0])\n",
        "y_true = th.tensor([2.0, 3.0, 4.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtyping import TensorType, patch_typeguard\n",
        "\n",
        "patch_typeguard()\n",
        "Scalar = TensorType[()]\n",
        "\n",
        "class MSELoss:\n",
        "    @typechecked\n",
        "    def forward(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"]) -> Scalar:\n",
        "        error = (y_pred - y_true)**2\n",
        "        return th.mean(error)"
      ],
      "metadata": {
        "id": "MuD-Flto2Iwl"
      },
      "id": "MuD-Flto2Iwl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = th.tensor([1.0, 3.0, 5.0])\n",
        "y_true = th.tensor([2.0, 3.0, 4.0])\n",
        "\n",
        "mse_loss = MSELoss()\n",
        "loss = mse_loss.forward(y_pred, y_true)\n",
        "\n",
        "print(f\"Предсказанные значения: {y_pred}\")\n",
        "print(f\"Истинные значения: {y_true}\")\n",
        "print(f\"MSE Loss: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9DFHHXo2YRb",
        "outputId": "e8872734-9a83-4119-ef89-f0f5b624038e"
      },
      "id": "_9DFHHXo2YRb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанные значения: tensor([1., 3., 5.])\n",
            "Истинные значения: tensor([2., 3., 4.])\n",
            "MSE Loss: 0.6666666865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7b6d63",
      "metadata": {
        "id": "4d7b6d63"
      },
      "source": [
        "## Задачи для самостоятельного решения"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705e742b",
      "metadata": {
        "id": "705e742b"
      },
      "source": [
        "### Cоздание полносвязных слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fe867c",
      "metadata": {
        "id": "36fe867c"
      },
      "source": [
        "<p class=\"task\" id=\"1\"></p>\n",
        "\n",
        "1\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте полносвязный слой из `n_neurons` нейронов с `n_features` весами у каждого нейрона (инициализируются из стандартного нормального распределения) и опциональным вектором смещения.\n",
        "\n",
        "$$y = xW^T + b$$\n",
        "\n",
        "Пропустите вектор `inputs` через слой и выведите результат. Результатом прогона сквозь слой должна быть матрица размера `batch_size` x `n_neurons`.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class Linear:\n",
        "#    def __init__(self, n_neurons: int, n_features: int, bias: bool = False) -> None:\n",
        "#        self.weights = th.randn(n_neurons, n_features)\n",
        "#        self.bias = th.randn(n_neurons)\n",
        "#\n",
        "#    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"n_neurons\"]:\n",
        "#        return th.mm(inputs, self.weights) # [\"bath\", \"n_features\"] * (n_features, n_neurons)"
      ],
      "metadata": {
        "id": "kcCxn5eVbhdy"
      },
      "id": "kcCxn5eVbhdy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    def __init__(self, n_features: int, n_neurons: int, bias: bool = False):\n",
        "        self.weights = th.randn(n_neurons, n_features)\n",
        "        self.bias = th.randn(n_neurons) if bias else th.zeros(n_neurons)\n",
        "\n",
        "    def forward(self, inputs: TensorType[\"batch\", \"n_features\"]) -> TensorType[\"batch\", \"n_neurons\"]:\n",
        "        return inputs @ self.weights.T + self.bias"
      ],
      "metadata": {
        "id": "BOyDZIHy_6_m"
      },
      "id": "BOyDZIHy_6_m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "n_features = 5\n",
        "n_neurons = 3\n",
        "\n",
        "inputs = th.randn(batch_size, n_features)\n",
        "linear_layer = Linear(n_features, n_neurons, bias=True)\n",
        "output = linear_layer.forward(inputs)\n",
        "\n",
        "print(f\"Размер выхода слоя: {output.shape} (ожидаем: {batch_size, n_neurons})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4G1Xi5XAYHA",
        "outputId": "e376f140-43ac-4afc-8703-8ac577c073c5"
      },
      "id": "U4G1Xi5XAYHA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер выхода слоя: torch.Size([4, 3]) (ожидаем: (4, 3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad52a4f",
      "metadata": {
        "id": "fad52a4f"
      },
      "source": [
        "<p class=\"task\" id=\"2\"></p>\n",
        "\n",
        "2\\. Используя решение предыдущей задачи, создайте 2 полносвязных слоя и пропустите тензор `inputs` последовательно через эти два слоя. Количество нейронов в первом слое выберите произвольно, количество нейронов во втором слое выберите так, чтобы результатом прогона являлась матрица `batch_size x 7`.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "input_features = 20\n",
        "inputs = th.randn(batch_size, input_features)\n",
        "\n",
        "layer1 = Linear(n_features=input_features, n_neurons=15, bias=True)\n",
        "layer2 = Linear(n_features=15, n_neurons=7, bias=True)\n",
        "\n",
        "output1 = layer1.forward(inputs)\n",
        "final_output = layer2.forward(output1)\n",
        "\n",
        "print(f\"Размер итогового выхода: {final_output.shape} (ожидаем: {batch_size, 7})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCO0EIMA5FS",
        "outputId": "021bfb0a-d54e-4405-dc0d-fbf4942a2bde"
      },
      "id": "tDCO0EIMA5FS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер итогового выхода: torch.Size([10, 7]) (ожидаем: (10, 7))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f89bb8e",
      "metadata": {
        "id": "1f89bb8e"
      },
      "source": [
        "### Создание функций активации"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3c912a6",
      "metadata": {
        "id": "d3c912a6"
      },
      "source": [
        "<p class=\"task\" id=\"3\"></p>\n",
        "\n",
        "3\\. Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации softmax:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/6d7500d980c313da83e4117da701bf7c8f1982f5)\n",
        "\n",
        "$$\\overrightarrow{x} = (x_1, ..., x_J)$$\n",
        "\n",
        "Создайте матрицу размера (4,3), заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации. Строки матрицы трактовать как выходы линейного слоя некоторого классификатора для 4 различных примеров. Функция должна применяться переданной на вход матрице построчно.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
        "        exps = th.exp(inputs)\n",
        "        sum_exps = th.sum(exps, dim=1, keepdim=True)\n",
        "        return exps / sum_exps"
      ],
      "metadata": {
        "id": "HfQdAN08CaRG"
      },
      "id": "HfQdAN08CaRG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_activation = Softmax()\n",
        "input_matrix = th.randn(4, 3)\n",
        "output_matrix = softmax_activation.forward(input_matrix)\n",
        "print(th.sum(output_matrix, dim=1))\n",
        "print(output_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkXhJ4hFPgC",
        "outputId": "87d22b76-80ad-496c-b25c-717a12eda068"
      },
      "id": "0HkXhJ4hFPgC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n",
            "tensor([[0.1259, 0.6943, 0.1798],\n",
            "        [0.5271, 0.0899, 0.3830],\n",
            "        [0.2232, 0.6180, 0.1588],\n",
            "        [0.4461, 0.2499, 0.3040]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a8acbae",
      "metadata": {
        "id": "1a8acbae"
      },
      "source": [
        "<p class=\"task\" id=\"4\"></p>\n",
        "\n",
        "4 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию активации ELU:\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/eb23becd37c3602c4838e53f532163279192e4fd)\n",
        "\n",
        "Создайте матрицу размера 4x3, заполненную числами из стандартного нормального распределения, и проверьте работоспособность функции активации.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ELU:\n",
        "    def __init__(self, alpha: float = 1.0):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs: TensorType[\"batch\", \"feats\"]) -> TensorType[\"batch\", \"feats\"]:\n",
        "        output = inputs.clone()\n",
        "        neg_indices = inputs < 0\n",
        "        output[neg_indices] = self.alpha * (th.exp(output[neg_indices]) - 1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "0OKSLSSVJpV5"
      },
      "id": "0OKSLSSVJpV5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elu_activation = ELU(alpha=1.0)\n",
        "input_matrix = th.randn(4, 3)\n",
        "output_matrix = elu_activation.forward(input_matrix)\n",
        "\n",
        "print(\"Входная матрица:\\n\", input_matrix)\n",
        "print(\"Матрица после ELU:\\n\", output_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UZgNINqQByU",
        "outputId": "96bdd0fc-17d8-4b2a-c245-feb9df849c60"
      },
      "id": "7UZgNINqQByU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Входная матрица:\n",
            " tensor([[ 0.4092,  2.3805,  1.5310],\n",
            "        [ 0.0853,  1.9395, -0.9296],\n",
            "        [-0.4913, -0.4839, -0.3274],\n",
            "        [-0.4648, -0.3639,  0.8862]])\n",
            "Матрица после ELU:\n",
            " tensor([[ 0.4092,  2.3805,  1.5310],\n",
            "        [ 0.0853,  1.9395, -0.6053],\n",
            "        [-0.3882, -0.3837, -0.2792],\n",
            "        [-0.3717, -0.3050,  0.8862]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa02fb0d",
      "metadata": {
        "id": "aa02fb0d"
      },
      "source": [
        "### Создание функции потерь"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab7e56a",
      "metadata": {
        "id": "bab7e56a"
      },
      "source": [
        "<p class=\"task\" id=\"5\"></p>\n",
        "\n",
        "5 Используя операции над матрицами и векторами из библиотеки `torch`, реализуйте функцию потерь CrossEntropyLoss:\n",
        "\n",
        "$$y_i = (y_{i,1},...,y_{i,k})$$\n",
        "\n",
        "<img src=\"https://i.ibb.co/93gy1dN/Screenshot-9.png\" width=\"200\">\n",
        "\n",
        "$$ CrossEntropyLoss = \\frac{1}{n}\\sum_{i=1}^{n}{L_i}$$\n",
        "где $y_i$ - вектор правильных ответов для примера $i$, $\\hat{y_i}$ - вектор предсказаний модели для примера $i$; $k$ - количество классов, $n$ - количество примеров в батче.\n",
        "\n",
        "Создайте полносвязный слой с 2 нейронами и прогнать через него батч `inputs`. Полученный результат пропустите через функцию активации Softmax. Посчитайте значение функции потерь, трактуя вектор `y` как вектор правильных ответов.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f683f102",
      "metadata": {
        "id": "f683f102"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss:\n",
        "    def forward(self, y_pred: TensorType[\"batch\", \"float\"], y_true: TensorType[\"batch\", \"int\"]) -> TensorType[()]:\n",
        "        batch_size = y_pred.shape[0]\n",
        "\n",
        "        correct_log_probs = th.log(y_pred[range(batch_size), y_true])\n",
        "        loss = -th.mean(correct_log_probs)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "n_features = 5\n",
        "n_neurons = 3\n",
        "\n",
        "inputs = th.randn(batch_size, n_features)\n",
        "y_true = th.tensor([0, 2, 1, 1])\n",
        "\n",
        "layer = Linear(n_features, n_neurons)\n",
        "logits = layer.forward(inputs)\n",
        "softmax = Softmax()\n",
        "y_pred = softmax.forward(logits)\n",
        "\n",
        "cross_entropy = CrossEntropyLoss()\n",
        "loss = cross_entropy.forward(y_pred, y_true)\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_dzjT3GUNGS",
        "outputId": "f41cb3ee-6b15-493e-8090-48b5e27373ff"
      },
      "id": "z_dzjT3GUNGS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7213234901428223"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9c82a1",
      "metadata": {
        "id": "7c9c82a1"
      },
      "source": [
        "<p class=\"task\" id=\"6\"></p>\n",
        "\n",
        "6 Модифицируйте MSE, добавив L2-регуляризацию.\n",
        "\n",
        "$$MSE_R = MSE + \\lambda\\sum_{i=1}^{m}w_i^2$$\n",
        "\n",
        "где $\\lambda$ - коэффициент регуляризации; $w_i$ - веса модели.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MSERegularized:\n",
        "    def __init__(self, lambda_: float):\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def data_loss(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"]) -> Scalar:\n",
        "        return th.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "    def reg_loss(self, weights: TensorType) -> Scalar:\n",
        "        return th.sum(weights ** 2)\n",
        "\n",
        "    def forward(self, y_pred: TensorType[\"batch\"], y_true: TensorType[\"batch\"], weights: TensorType) -> Scalar:\n",
        "        return self.data_loss(y_pred, y_true) + self.lambda_ * self.reg_loss(weights)"
      ],
      "metadata": {
        "id": "rupnZI8_YH6X"
      },
      "id": "rupnZI8_YH6X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = th.tensor([0.5, -1.2, 0.8, 2.1])\n",
        "\n",
        "y_pred = th.tensor([1.5, 2.8])\n",
        "y_true = th.tensor([1.0, 3.0])\n",
        "\n",
        "lambda_ = 0.01\n",
        "\n",
        "regularized_loss_func = MSERegularized(lambda_=lambda_)\n",
        "total_loss = regularized_loss_func.forward(y_pred, y_true, weights)\n",
        "\n",
        "mse = ((1.5-1.0)**2 + (2.8-3.0)**2) / 2\n",
        "l2 = 0.5**2 + (-1.2)**2 + 0.8**2 + 2.1**2\n",
        "expected_total_loss = mse + lambda_ * l2\n",
        "\n",
        "print(f\"MSE: {regularized_loss_func.data_loss(y_pred, y_true)}\")\n",
        "print(f\"L2: {regularized_loss_func.reg_loss(weights)}\")\n",
        "print(f\"Итог: {total_loss}\")\n",
        "print(f\"Ожидание: {expected_total_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbFChJWZYcGT",
        "outputId": "4074b36b-a28a-4bed-ee99-2cfbf8d0ecfd"
      },
      "id": "YbFChJWZYcGT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.14500001072883606\n",
            "L2: 6.739999771118164\n",
            "Итог: 0.21240000426769257\n",
            "Ожидание: 0.21240000000000003\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}